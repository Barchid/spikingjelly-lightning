{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spikingjelly-lightning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWOXfSctVVz2"
      },
      "source": [
        "# Train Spiking Neural Network on Google Colab\n",
        "\n",
        "The objective of this notebook is to give you the tools to conduct experiments by training a convolutional spiking neural network (CSNN) using Google Colab. The following example uses a template project (https://github.com/Barchid/spikingjelly-lightning) to train a Lenet5-like CSNN using a library called `spikingjelly` (for SNN simulation) and `pytorch-lightning`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeCza8U4ArcI"
      },
      "source": [
        "## Setup\n",
        "\n",
        "First and foremost, let's configure your Google Colab session. You have to enable a GPU runtime. On your Colab tabs (top of the screen), go to `Runtime` ▶ `Change runtime type` ▶ `Hardware accelerator` select \"GPU\" ▶ Click on `Save`.\n",
        "\n",
        "Now it's done, let's clone the project repository and the required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGf2zpFky3hQ"
      },
      "source": [
        "!pip install spikingjelly pytorch-lightning torchmetrics tonic\n",
        "!git clone https://github.com/Barchid/spikingjelly-lightning\n",
        "\n",
        "# Move to the cloned project\n",
        "%cd spikingjelly-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzPOxeomeR5-"
      },
      "source": [
        "# pull some changes if you pushed changes after cloning the project\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTknJd3SKAm-"
      },
      "source": [
        "## Program arguments\n",
        "The project provides a lot of arguments to shape the training to your needs. A wide majority of them are provided by pytorch-lightning, and some are specific to the CSNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S0BWfF3KvxX"
      },
      "source": [
        "# Print out the available parameters.\n",
        "!python main.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ojFYSK_LTmi"
      },
      "source": [
        " Let's take a look at the most interesting for our example :\n",
        "\n",
        "- **Related to `pytorch-lightning` :**\n",
        "  - `--default_root_dir`: path of the directory where all the tensoboard logs, checkpoints, etc will be stored. Prefer a path that starts with `experiments/....` to make it cleaner.\n",
        "  - `--gpus` and `--auto_select_gpus`: helps you make the choice of GPU to run your CSNN. **On Colab, always use `--gpus=1 --auto_select_gpus`** since you have access to one GPU.\n",
        "  - `--max_epochs` : number of epochs to run your training experiment.\n",
        "\n",
        "- **Related to the CSNN**:\n",
        "  - `--timesteps`: number of timesteps to simulate your CSNN. This argument is mandatory.\n",
        "  - `--learning_rate`: learning rate for your training.\n",
        "  - `--batch_size`: the batch size for your experiment\n",
        "  - `--neuron_model`: model of spiking neuron that will be used for your project. Choices are : LIF/IF/PLIF spiking neurons.\n",
        "  - `--bias`: indicates if you will use bias parameters in your network. *Warning: bias are not bio-plausible and hard to implement on neuromorphic hardware.*\n",
        "\n",
        "- **Related to the program**:\n",
        "  - `--ckpt_path`: path of a checkpoint file containing a trained CSNN. It can be used to test your network's performance after training.\n",
        "  - `--mode`: mode of your program. There are values possible. `--mode=\"train\"` to train your CSNN or `--mode=\"validate\"` to perform a validation/test of your CSNN (mostly used coupled with `--ckpt_path`).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cE3f0NzjR3xN"
      },
      "source": [
        "## Training\n",
        "Now we know a little bit about the training, we can launch a typical training with the standard arguments for a Google Colab session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECGduLuVTKT_"
      },
      "source": [
        "!python main.py --default_root_dir=\"experiments/typical_training\" --gpus=1 --auto_select_gpus --timesteps=8 --learning_rate=1e-3 --max_epochs=2 --mode=\"train\" --neuron_model=\"LIF\" --batch_size=64 --bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVFCpLehTvlF"
      },
      "source": [
        "## Validation\n",
        "\n",
        "After training, we obtain a checkpoint of the best performing model. We can evaluate this checkpoint with a validation step of the trained CSNN with\n",
        "`--mode=\"validate\"` and `--ckpt_path=\"...\"`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIiouffwzcHU"
      },
      "source": [
        "!python main.py --default_root_dir=\"experiments/typical_training\" --mode=\"validate\" --timesteps=8 --gpus=1 --auto_select_gpus --ckpt_path=\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uQbyu74UrGX"
      },
      "source": [
        "## Useful features\n",
        "\n",
        "`pytorch-lightning` comes with a lot of features that can help you build and optimize your network. I strongly recommend you to take a look at the documentation (https://pytorch-lightning.readthedocs.io/en/latest/) to know more about it. But let's make a quick crash course of some features you can try with the project using the built-in arguments :\n",
        "\n",
        "### Learning Rate Finder\n",
        "\n",
        "Finding a good learning rate can be difficult. The following argument can help you find a good learning rate automatically: `--mode=\"lr_find\"` ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQKS9XQLLOZC"
      },
      "source": [
        "!python main.py --default_root_dir=\"experiments/typical_training\" --gpus=1 --auto_select_gpus --timesteps=8 --mode=\"lr_find\" --neuron_model=\"LIF\" --batch_size=64 --bias"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uWNMfibbBq7"
      },
      "source": [
        "### Debugging your model\n",
        "Like any programs, a neural networks are not protected from bugs in their implementation. However, contrary to common programs, it is hard to find bugs or even detect there is a problem in the implementation. You won't have an exception that will pop out of nowhere.\n",
        "\n",
        "Hopefully, a simple debugging strategy can be used to check if your neural network actually learns something. It consists of overfitting a very small number of batches and check if the loss quickly goes to 0 (or very close to 0). If it is not the case, it means that your model has a problem that prevents it from learning anything.\n",
        "\n",
        "Here, we will use this technique with the flag `--overfit_batches=4`, to overfit our model on 4 batches.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2NMUtRKdRej"
      },
      "source": [
        "!python main.py --default_root_dir=\"experiments/typical_training\" --gpus=1 --auto_select_gpus --timesteps=8 --learning_rate=1e-3 --max_epochs=50 --overfit_batches=4 --mode=\"train\" --neuron_model=\"LIF\" --batch_size=64 --bias"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}